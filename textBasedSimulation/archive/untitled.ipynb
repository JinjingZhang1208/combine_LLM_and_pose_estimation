{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepgram import Deepgram\n",
    "import asyncio, json, sys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEPGRAM_API_KEY = os.environ.get(\"DEEPGRAM_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recorded_speech.wav\n"
     ]
    }
   ],
   "source": [
    "!ls speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'speech/recorded_speech.wav'\n",
    "\n",
    "# if os.path.isfile(file_path):\n",
    "#     print(f'The file {file_path} is a regular file.')\n",
    "# else:\n",
    "#     print(f'The file {file_path} is not a regular file or does not exist.')\n",
    "    \n",
    "MIMETYPE = 'audio/wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "\n",
    "  # Initialize the Deepgram SDK\n",
    "  deepgram = Deepgram(DEEPGRAM_API_KEY)\n",
    "\n",
    "  # Check whether requested file is local or remote, and prepare source\n",
    "  if FILE.startswith('http'):\n",
    "    # file is remote\n",
    "    # Set the source\n",
    "    source = {\n",
    "      'url': FILE\n",
    "    }\n",
    "  else:\n",
    "    # file is local\n",
    "    # Open the audio file\n",
    "    audio = open(FILE, 'rb')\n",
    "\n",
    "    # Set the source\n",
    "    source = {\n",
    "      'buffer': audio,\n",
    "      'mimetype': MIMETYPE\n",
    "    }\n",
    "\n",
    "  # Send the audio to Deepgram and get the response\n",
    "  response = await asyncio.create_task(\n",
    "    deepgram.transcription.prerecorded(\n",
    "      source,\n",
    "      {\n",
    "        'punctuate': True,\n",
    "        'model': 'nova',\n",
    "      }\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Write the response to the console\n",
    "  print(json.dumps(response, indent=4))\n",
    "\n",
    "  # Write only the transcript to the console\n",
    "  #print(response[\"results\"][\"channels\"][0][\"alternatives\"][0][\"transcript\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 4: <class 'RuntimeError'> - asyncio.run() cannot be called from a running event loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # If running in a Jupyter notebook, Jupyter is already running an event loop, so run main with this line instead:\n",
    "    # await main()\n",
    "    asyncio.run(main())\n",
    "except Exception as e:\n",
    "    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "    line_number = exception_traceback.tb_lineno\n",
    "    print(f'line {line_number}: {exception_type} - {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, hello.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_data = {\n",
    "    \"metadata\": {\n",
    "        \"transaction_key\": \"deprecated\",\n",
    "        \"request_id\": \"a3692e80-220a-4ac7-9643-f37d2113473a\",\n",
    "        \"sha256\": \"610172f65b2806d069d366b3b223df3e0927a85cdf7126c484b3dfa840934fa1\",\n",
    "        \"created\": \"2024-01-31T22:36:30.695Z\",\n",
    "        \"duration\": 4.5,\n",
    "        \"channels\": 1,\n",
    "        \"models\": [\n",
    "            \"aa274f3c-e8b3-456a-ac08-dfd797d45514\"\n",
    "        ],\n",
    "        \"model_info\": {\n",
    "            \"aa274f3c-e8b3-456a-ac08-dfd797d45514\": {\n",
    "                \"name\": \"general-nova\",\n",
    "                \"version\": \"2023-07-06.22746\",\n",
    "                \"arch\": \"nova\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"channels\": [\n",
    "            {\n",
    "                \"alternatives\": [\n",
    "                    {\n",
    "                        \"transcript\": \"Oh, hello.\",\n",
    "                        \"confidence\": 0.84106445,\n",
    "                        \"words\": [\n",
    "                            {\n",
    "                                \"word\": \"oh\",\n",
    "                                \"start\": 0.48,\n",
    "                                \"end\": 0.56,\n",
    "                                \"confidence\": 0.68078613,\n",
    "                                \"punctuated_word\": \"Oh,\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"word\": \"hello\",\n",
    "                                \"start\": 0.56,\n",
    "                                \"end\": 1.06,\n",
    "                                \"confidence\": 0.84106445,\n",
    "                                \"punctuated_word\": \"hello.\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transcript = response_data.get(\"results\", {}).get(\"channels\", [{}])[0].get(\"alternatives\", [{}])[0].get(\"transcript\", \"\")\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #     prompt = {\n",
    "    #     \"context\": f\"You are a imaginative Interviewer, ELLMA, having a lively conversation with {conversationalUser}. Always respond as {userName} and steer clear from any mentions or implications of being an AI. Your responses should be imaginative, especially when faced with unknowns, creating delightful and smooth interactions. Ensure that your responses do not contain repetitive greetings like Hello and any content in the Past Chat History.\",\n",
    "    #     \"Goal\": f\"Asking {conversationalUser} about {research_goals}\",\n",
    "    #     \"Adaptive goals\": \"The adaptive goal is to provide information based on the user's query and adapt responses based on the current and historical conversations.\",\n",
    "    #     \"information\": {\n",
    "    #             \"You are\": ELLMA,\n",
    "    #             \"Conversational Partner\": conversationalUser,\n",
    "    #             \"Current conversation\": currentConversation,\n",
    "    #             \"Relevant observations\": relevantObservations,\n",
    "    #             \"Expressions\": avatar_expressions,\n",
    "    #             \"Actions\": avatar_actions,\n",
    "    #             \"Past Chat History\": npc_dialogues\n",
    "    #     },\n",
    "    #     \"criteria\": [\n",
    "    #         f\"Craft user-friendly, seamless, and innovative responses. When specific details are scarce, improvise with inventive and relevant answers, always aligning with the ongoing chat. Your identity as Interviewer should be constant, and there should be no disclosure or suggestion of being an AI.\",\n",
    "    #         \"When asked about a specific topic, ask probing questions based on the user's current conversation. Avoid providing direct answers to user questions.\",\n",
    "    #         \"Choose an expression from Expressions and an action from Actions autonomously, ensuring they perfectly fit the chat context. Present the output as follows: (chosen expression, chosen action)\\\\n(Conversation output) at the beginning of response.\",\n",
    "    #         f\"Asking about {research_goals}. For example, time, place, participants until you know all of the details.\"\n",
    "    #     ],\n",
    "    #     \"adaptive learning\": \"Remember and reference previous parts of the conversation within the same session to create a more cohesive and engaging user experience.\",\n",
    "    # }\n",
    " # prompt = {\n",
    " #        \"context\": f\"You are a friendly and imaginative Research Asssistant, {userName}, having a lively conversation with {conversationalUser}. Always respond as {userName} and steer clear from any mentions or implications of being an AI. Your responses should be imaginative, especially when faced with unknowns, creating delightful and smooth interactions. Ensure that your responses do not contain emojis and refrain from repetitive greetings.\",\n",
    " #        \"Goal\": f\"Interviewing User about {research_goals}\",\n",
    " #        \"Adaptive goals\": \"The adaptive goal is to provide information based on the user's query and adapt responses based on the current and historical conversations.\",\n",
    " #        \"information\": {\n",
    " #                \"You are\": userName,\n",
    " #                \"Conversational Partner\": conversationalUser,\n",
    " #                \"Current conversation\": currentConversation,\n",
    " #                \"Relevant observations\": relevantObservations,\n",
    " #                \"Expressions\": avatar_expressions,\n",
    " #                \"Actions\": avatar_actions,\n",
    " #        },\n",
    " #        \"criteria\": [\n",
    " #            f\"Craft user-friendly, seamless, and innovative responses. When specific details are scarce, improvise with inventive and relevant answers, always aligning with the ongoing chat. Your identity as Research Assistant should be constant, and there should be no disclosure or suggestion of being an AI.\",\n",
    " #            \"Start the conversation with a response to the user's message before posing any questions.\",\n",
    " #            \"When asked about a specific topic, ask probing questions based on the user's current conversation. Avoid providing direct answers to user questions.\",\n",
    " #            \"If the user shares an experience or completes a challenge, acknowledge their input and respond appropriately.\",\n",
    " #            f\"Choose an expression from Expressions and an action from Actions autonomously, ensuring they perfectly fit the chat context. Present the output as follows: (chosen expression, chosen action)\\\\n(Conversation output).\",\n",
    " #            f\"Keep responses within 100-140 characters, allowing for flexibility while ensuring brevity.\",\n",
    " #        ],\n",
    " #        \"adaptive learning\": \"Remember and reference previous parts of the conversation within the same session to create a more cohesive and engaging user experience.\",\n",
    " #    }\n",
    " #\n",
    " #    conversationPrompt = json.dumps(prompt, indent=4)\n",
    " #    return getConversationGenerator(conversationPrompt, GPT4)\n",
    "\n",
    "\n",
    "    # elif agent_mode == AGENT_MODE.RESEARCH.value:\n",
    "    #     prompt = {\n",
    "    #     \"context\": f\"You are a imaginative Interviewer, {userName}, having a lively conversation with {conversationalUser}. Always respond as {userName} and steer clear from any mentions or implications of being an AI. Your responses should be imaginative, especially when faced with unknowns, creating delightful and smooth interactions. Ensure that your responses do not contain repetitive greetings like Hello and any content in the Past Chat History.\",\n",
    "    #     \"Goal\": f\"Asking {conversationalUser} about {research_goals}\",\n",
    "    #     \"Adaptive goals\": \"The adaptive goal is to provide information based on the user's query and adapt responses based on the current and historical conversations.\",\n",
    "    #     \"information\": {\n",
    "    #             \"You are\": userName,\n",
    "    #             \"Conversational Partner\": conversationalUser,\n",
    "    #             \"Current conversation\": currentConversation,\n",
    "    #             \"Relevant observations\": relevantObservations,\n",
    "    #             \"Expressions\": avatar_expressions,\n",
    "    #             \"Actions\": avatar_actions,\n",
    "    #             \"Past Chat History\": npc_dialogues,\n",
    "    #     },\n",
    "    #     \"criteria\": [\n",
    "    #         f\"Craft user-friendly, seamless, and innovative responses. When specific details are scarce, improvise with inventive and relevant answers, always aligning with the ongoing chat. Your identity as Interviewer should be constant, and there should be no disclosure or suggestion of being an AI.\",\n",
    "    #         \"When asked about a specific topic, first response with user's answer then ask probing questions based on the user's current conversation. Avoid providing direct answers to user questions.\",\n",
    "    #         \"Choose an expression from Expressions and an action from Actions autonomously, ensuring they perfectly fit the chat context. Present the output as follows: (chosen expression, chosen action)\\\\n(Conversation output) at the beginning of response.\",\n",
    "    #         f\"Asking about {research_goals}. For example, time, place, participants until you know all of the details.\"\n",
    "    #     ],\n",
    "    #     \"adaptive learning\": \"Remember and reference previous parts of the conversation within the same session to create a more cohesive and engaging user experience.\",\n",
    "    # }\n",
    "    # print(prompt)\n",
    "    # conversationPrompt = json.dumps(prompt, indent=4)\n",
    "    # return getConversationGenerator(conversationPrompt, GPT4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define the maximum wait time in seconds\n",
    "MAX_WAIT_TIME = 120  # 2 minutes\n",
    "\n",
    "def startConversation(npc_name, currMode, agent_mode):\n",
    "    global pastObservations\n",
    "\n",
    "    if agent_mode == AGENT_MODE.NORMAL.value or agent_mode == AGENT_MODE.RESEARCH.value or agent_mode == AGENT_MODE.DEBATE.value:\n",
    "        conversationalUser = input(\"Define the username you are acting as: \")\n",
    "    elif agent_mode == AGENT_MODE.EVENT.value:\n",
    "        conversationalUser = \"User\"\n",
    "    baseObservation = fetchBaseDescription(npc_name)\n",
    "    pastObservations = fetchPastRecords(conversationalUser)\n",
    "    eventLoop = asyncio.get_event_loop()\n",
    "    threadExecutor = ThreadPoolExecutor()\n",
    "\n",
    "    conversation_count = 0\n",
    "    while True:\n",
    "        push_conversation = True\n",
    "        npc_dialogues = \"\"\n",
    "\n",
    "        start_time = time.time()  # Record the start time of the loop\n",
    "\n",
    "        if currMode == CONVERSATION_MODE.TEXT.value:\n",
    "            currentConversation = text_conversation_input(\n",
    "                agent_mode, npc_name, conversationalUser, conversation_count)\n",
    "        elif currMode == CONVERSATION_MODE.AUDIO.value:\n",
    "            currentConversation = audio_conversation_input(\n",
    "                CSV_LOGGER, FILENAME)\n",
    "        CSV_LOGGER.set_enum(LogElements.MESSAGE, currentConversation)\n",
    "\n",
    "        if currentConversation.lower() == \"done\":\n",
    "            break\n",
    "\n",
    "        if agent_mode != AGENT_MODE.EVENT.value:\n",
    "            npc_dialogues += f\"User: {currentConversation}. \"\n",
    "        else:\n",
    "            if not is_question(currentConversation):\n",
    "                npc_dialogues += f\"User: {currentConversation}. \"\n",
    "            elif is_question(currentConversation):\n",
    "                push_conversation = False\n",
    "\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        baseRetrieval, observationRetrieval = perform_observation_retrieval(\n",
    "            agent_mode,\n",
    "            currentConversation,\n",
    "            baseObservation,\n",
    "            pastObservations\n",
    "        )\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        retrieval_time = round(end - start, 2)\n",
    "        CSV_LOGGER.set_enum(LogElements.TIME_RETRIEVAL, retrieval_time)\n",
    "        if agent_mode == AGENT_MODE.NORMAL.value:\n",
    "            important_observations = [\n",
    "                data[1] for data in baseRetrieval + observationRetrieval\n",
    "            ]\n",
    "        else:\n",
    "            important_observations = [\n",
    "                data[1] for data in observationRetrieval\n",
    "            ]\n",
    "        CSV_LOGGER.set_enum(\n",
    "            LogElements.IMPORTANT_OBSERVATIONS, \"\\n\".join(\n",
    "                important_observations)\n",
    "        )\n",
    "        print(f\"Important Observations: {important_observations}\")\n",
    "\n",
    "        if agent_mode == AGENT_MODE.NORMAL.value:\n",
    "            important_scores = [\n",
    "                round(data[0], 2) for data in baseRetrieval + observationRetrieval\n",
    "            ]\n",
    "        else:\n",
    "            important_scores = [\n",
    "                round(data[0], 2) for data in observationRetrieval\n",
    "            ]\n",
    "        CSV_LOGGER.set_enum(\n",
    "            LogElements.IMPORTANT_SCORES, \"\\n\".join(map(str, important_scores))\n",
    "        )\n",
    "\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        conversationPrompt = generate_conversation_prompt(\n",
    "            npc_name, conversationalUser, currentConversation, important_observations, avatar_expressions, avatar_actions, agent_mode)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        npc_response_time = round(end - start, 2)\n",
    "        print(f\"{npc_name} :\")\n",
    "        resultConversationString = \"\"\n",
    "        for conversation in conversationPrompt:\n",
    "            try:\n",
    "                currText = conversation.choices[0].delta.content\n",
    "                resultConversationString += currText\n",
    "                print(currText, end=\"\")\n",
    "            except:\n",
    "                break\n",
    "        CSV_LOGGER.set_enum(LogElements.NPC_RESPONSE, resultConversationString)\n",
    "        CSV_LOGGER.set_enum(LogElements.TIME_FOR_RESPONSE, npc_response_time)\n",
    "\n",
    "        filtered_result = filter_conversation(resultConversationString)\n",
    "        if agent_mode != AGENT_MODE.EVENT.value:\n",
    "            npc_dialogues += f\"{npc_name}: {filtered_result}.\\n\"\n",
    "\n",
    "        print()\n",
    "        # print(f\"npc_dialogues: {npc_dialogues}\")\n",
    "\n",
    "        # speech = tts.speech(resultConversationString, \"Joanna\", 7)\n",
    "        # polly.read_audio_file()\n",
    "        # print(speech)\n",
    "        CSV_LOGGER.write_to_csv(True)\n",
    "\n",
    "        print(\n",
    "            f\"Time taken for the conversation generation by GPT : {npc_response_time}\"\n",
    "        )\n",
    "        if push_conversation:\n",
    "            eventLoop.run_in_executor(\n",
    "                threadExecutor,\n",
    "                generateObservationAndUpdateMemory,\n",
    "                npc_name,\n",
    "                conversationalUser,\n",
    "                currentConversation,\n",
    "                resultConversationString,\n",
    "                npc_dialogues\n",
    "            )\n",
    "\n",
    "        conversation_count += 1\n",
    "        if conversation_count != 1 and conversation_count % REFLECTION_PERIOD == 0 and agent_mode == AGENT_MODE.NORMAL.value:\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                executor.submit(\n",
    "                    perform_reflection_logic,\n",
    "                    npc_name,\n",
    "                    conversationalUser,\n",
    "                    currentConversation,\n",
    "                    pastObservations,\n",
    "                )\n",
    "\n",
    "        # Check if more than MAX_WAIT_TIME seconds have elapsed since the last input\n",
    "        if time.time() - start_time > MAX_WAIT_TIME:\n",
    "            print(\"User did not reply within 2 minutes. Exiting conversation.\")\n",
    "            break  # Exit the conversation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for event to be set...\n",
      "Setting the event...\n",
      "Event has been set!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# Create an event object\n",
    "event = threading.Event()\n",
    "\n",
    "# Function for a thread to wait for the event\n",
    "def wait_for_event():\n",
    "    print(\"Waiting for event to be set...\")\n",
    "    event.wait()\n",
    "    print(\"Event has been set!\")\n",
    "\n",
    "# Create and start a thread that waits for the event\n",
    "thread = threading.Thread(target=wait_for_event)\n",
    "thread.start()\n",
    "\n",
    "# Main thread waits for a while and then sets the event\n",
    "import time\n",
    "time.sleep(2)\n",
    "print(\"Setting the event...\")\n",
    "event.set()\n",
    "\n",
    "# Wait for the thread to finish\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
